%%% 3_1
%~ Для первой обучающей выборки построить и обучить двухслойную сеть прямого рас-
%~ пространения, которая будет правильно относить точки к двум классам. Классы являются
%~ линейно неразделимыми. Точки располагаются по каждой оси в диапазоне [-1.5;1.5].
clear;
clc;

%% 1.1
%~ Обучающее множество занести в отчет. Отобразить входное множество и эталонное
%~ распределение по классам. Для отображения необходимо номер класса −1 заменить на 0.

P = [0.1 0.6; 0 1.4; -0.9 -1.2; -1.2 -1.4; -0.3 -0.2; -0.5 0.7; 1.2 0.9; -1 1.4; 0.5 -1.1; 0 -1.3; 1.3 0; 1 -0.1]';


T = [-1 -1 1 1 1 1 -1 1 1 1 -1 1];
T(T == -1) = 0; 
plotpv(P, T)

%% 1.2
%~ Создать сеть с помощью функции feedforwardnet. Сконфигурировать сеть под обуча-
%~ ющее множество с помощью функции configure. Число нейронов скрытого слоя задать рав-
%~ ным 5. Использовать активационные функции, заданные по умолчанию. Задать RProp в ка-
%~ честве алгоритма обучения сети . При решении задачи классификации не разбивать обуча-
%~ ющую выборку на обучающее, контрольное, и тестовое подмножества (net.divideFcn = ”).
%~ Отобразить структуру сети.
%~ По умолчанию активационной функцией выходного слоя является линейная функция.
%~ Выход сети преобразуется к номеру класса по правилу signum.

net = feedforwardnet(5, 'trainrp');
net = configure(net, P, T);
net.divideFcn='';
% display(net);

%% 1.3
%~ Инициализировать сеть с помощью функции, заданной по умолчанию. Занести в
%~ отчет весовые коэффициенты и смещения для двух слоев.

net = init(net);

net_IW = net.IW{1,1}
net_b = net.b{1}
net_LV = net.LW{2,1}
net_b = net.b{2}
view(net)

%% 1.4
%~ Задать параметры обучения: число эпох обучения (net.trainParam.epochs) равно 600,
%~ предельное значение критерия обучения (net.trainParam.goal) равно 10^-5 .

net.trainParam.epochs = 600;
net.trainParam.goal = 1e-5;

%% 1.5
%~ Провести обучение сети с помощью функции train. Если необходимо, то произ-
%~ вести обучение несколько раз. Если результаты классификации неудовлетворительные, то
%~ увеличить число эпох обучения или уменьшить предельное значение критерия обучения.
%~ Занести в отчет весовые коэффициенты и смещения для двух слоев. Занести в отчет график
%~ Performance и окно Neural Network Training.
net = train(net, P, T);

net_IW = net.IW{1,1}
net_b = net.b{1}
net_LV = net.LW{2,1}
net_b = net.b{2}

%% 1.6
%~ Проверить качество обучения: случайным образом задать 5 точек и классифици-
%~ ровать их. Отобразить сетку, дополнительные точки, обучающую выборку, и результаты
%~ распределения по классам. Результаты занести в отчет.

points = rands(2, 5);
res = sim(net, points);
res(res < 0) = 0; 
res(res >= 0) = 1; 
plotpv(horzcat(P, points), horzcat(T, res)), grid

waitforbuttonpress
quit

